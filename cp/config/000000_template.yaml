data:
  config: #config for data
    attr1: &attr1 10
  config_per_dataset_dict:
    dataset_name:
      preprocessor_class_meta_list: 
        - name: ['preprocessor', 'Preprocessor']
          args: {}
#####################################################################################################
dataloader:
  train:
    args:
      batch_size: 16
      num_workers: 4
    dataset_class_meta:
      name: ['file_name', 'class_name']
      args: {}
    #collater_class_meta:
    #  name: ['file_name', 'class_name']
    #  args: {}
  valid:
    args:
      batch_size: 16
      num_workers: 4
      shuffle: False
      drop_last: True
    dataset_class_meta:
      name: ['file_name', 'class_name']
      args: {}
  #test:
  #  args:
  #    batch_size: 16
  #    num_workers: 4
  #    shuffle: False
  #    drop_last: True
  #  dataset_class_meta:
  #    name: ['file_name', 'class_name']
  #    args: {}
#####################################################################################################
model:
  class_meta:
    name: ['file_name', 'class_name']
    args: {}
    #key_name1: #generator
      #name: ['file_name1', 'class_name1']
      #args: {}
    #key_name2: #discriminator
      #name: ['file_name2', 'class_name2']
      #args: {}
#####################################################################################################
train:
  #total_epoch: 100000
  #total_step: 100000
  #save_model_step_interval: 500

  class_meta:
    name: ['trainer', 'Trainer']
    args: {}
      #model_ckpt_path: 'step.pth'
      #use_ema: False

  optimizer: 
    class_meta: 
      name : 'AdamW'
      args :
        lr: 0.0008
        betas: [0.9,0.98]
        weight_decay: 0.0
    #key_name1: #generator
    #  name: AdamW
    #  args: {'lr': 0.00005, betas: [0.8, 0.99]}
    #  model_name_list: ['generator', 'model_name2'...]
    #key_name2: #discriminator
    #  name: AdamW
    #  args: {'lr': 0.0001, betas: [0.8, 0.99]}
    #  model_name_list: ['discriminator', 'model_name2'...]

  scheduler:
    class_meta: 
      name: "StepLR" #["inverse_lr", "InverseLR"]
      args:
        step_size: 20000
        gamma: 0.5
    interval: 'step' # Literal['step', 'epoch']
    frequency: 1

  loss:
    loss_name: # for specifying loss
      class_meta:
        name : 'L1Loss'
        args : {}
      #pred_name: '' # if model's output is dict, you can specify the key
      #target_name: '' # if target is dict, you can specify the key
      weight: 1
#####################################################################################################
inference:
  class_meta:
    name: ['inferencer', 'Inferencer']
    args: {}
#####################################################################################################
evaluate:
  class_meta:
    name: ['evaluator', 'Evaluator']
    args: 
      source_dir: ''