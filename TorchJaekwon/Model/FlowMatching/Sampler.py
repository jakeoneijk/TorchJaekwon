'''
Source: https://github.com/Stability-AI/stable-audio-tools
'''
import torch
from tqdm import tqdm, trange

import math

class Sampler:
    @staticmethod
    @torch.no_grad()
    def discrete_euler(model, x, steps, sigma_max=1, callback=None, dist_shift=None, **extra_args):
        """Draws samples from a model given starting noise. Euler method"""

        # Make tensor of ones to broadcast the single t values
        ts = x.new_ones([x.shape[0]])

        # Create the noise schedule
        t = torch.linspace(sigma_max, 0, steps + 1)

        if dist_shift is not None:
            t = dist_shift.time_shift(t, x.shape[-1])

        #alphas, sigmas = 1-t, t

        for i, (t_curr, t_prev) in enumerate(tqdm(zip(t[:-1], t[1:]))):
            # Broadcast the current timestep to the correct shape
            t_curr_tensor = t_curr * torch.ones(
                (x.shape[0],), dtype=x.dtype, device=x.device
            )
            dt = t_prev - t_curr  # we solve backwards in our formulation
            v = model(x, t_curr_tensor, **extra_args)
            x = x + dt * v

            if callback is not None:
                denoised = x - t_prev * v
                callback({'x': x, 't': t_curr, 'sigma': t_curr, 'i': i+1, 'denoised': denoised })

        # If we are on the last timestep, output the denoised data
        return x

    @staticmethod
    @torch.no_grad()
    def rk4(model, x, steps, sigma_max=1, callback=None, dist_shift=None, **extra_args):
        """Draws samples from a model given starting noise. 4th-order Runge-Kutta"""

        # Make tensor of ones to broadcast the single t values
        ts = x.new_ones([x.shape[0]])

        # Create the noise schedule
        t = torch.linspace(sigma_max, 0, steps + 1)

        if dist_shift is not None:
            t = dist_shift.time_shift(t, x.shape[-1])

        #alphas, sigmas = 1-t, t

        for i, (t_curr, t_prev) in enumerate(tqdm(zip(t[:-1], t[1:]))):
            # Broadcast the current timestep to the correct shape
            t_curr_tensor = t_curr * ts
            dt = t_prev - t_curr  # we solve backwards in our formulation
            
            k1 = model(x, t_curr_tensor, **extra_args)
            k2 = model(x + dt / 2 * k1, (t_curr + dt / 2) * ts, **extra_args)
            k3 = model(x + dt / 2 * k2, (t_curr + dt / 2) * ts, **extra_args)
            k4 = model(x + dt * k3, t_prev * ts, **extra_args)
            
            x = x + dt / 6 * (k1 + 2 * k2 + 2 * k3 + k4)

            if callback is not None:
                denoised = x - t_prev * k4
                callback({'x': x, 't': t_curr, 'sigma': t_curr, 'i': i+1, 'denoised': denoised })

        # If we are on the last timestep, output the denoised data
        return x

    @staticmethod
    @torch.no_grad()
    def flow_dpmpp(model, x, steps, sigma_max=1, callback=None, dist_shift=None, **extra_args):
        """Draws samples from a model given starting noise. DPM-Solver++ for RF models"""

        # Make tensor of ones to broadcast the single t values
        ts = x.new_ones([x.shape[0]])

        # Create the noise schedule
        t = torch.linspace(sigma_max, 0, steps + 1)

        if dist_shift is not None:
            t = dist_shift.time_shift(t, x.shape[-1])

        old_denoised = None

        log_snr = lambda t: ((1-t) / t).log()

        for i in trange(len(t) - 1, disable=False):
            denoised = x - t[i] * model(x, t[i] * ts, **extra_args)
            if callback is not None:
                callback({'x': x, 'i': i, 'sigma': t[i], 'sigma_hat': t[i], 'denoised': denoised})
            t_curr, t_next = t[i], t[i + 1]
            alpha_t = 1-t_next
            h = log_snr(t_next) - log_snr(t_curr)
            if old_denoised is None or t_next == 0:
                x = (t_next / t_curr) * x - alpha_t * (-h).expm1() * denoised
            else:
                h_last = log_snr(t_curr) - log_snr(t[i - 1])
                r = h_last / h
                denoised_d = (1 + 1 / (2 * r)) * denoised - (1 / (2 * r)) * old_denoised
                x = (t_next / t_curr) * x - alpha_t * (-h).expm1() * denoised_d
            old_denoised = denoised
        return x

class DistributionShift:
    def __init__(self, base_shift=0.5, max_shift=1.15, max_length=4096, min_length=256, use_sine=False):
        self.base_shift = base_shift
        self.max_shift = max_shift
        self.max_length = max_length
        self.min_length = min_length
        self.use_sine = use_sine
    
    def time_shift(self, t: torch.Tensor, seq_len: int):
        sigma = 1.0
        mu = - (self.base_shift + (self.max_shift - self.base_shift) * (seq_len - self.min_length) / (self.max_length - self.min_length))
        t_out = 1 - math.exp(mu) / (math.exp(mu) + (1 / (1 - t) - 1) ** sigma)

        if self.use_sine:
            t_out = torch.sin(t_out * math.pi / 2)

        return t_out